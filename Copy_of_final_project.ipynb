{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GilenW/CSE151A_FINAL_PROJECT/blob/main/Copy_of_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJik-zwqXYR-"
      },
      "outputs": [],
      "source": [
        "# !pip3 install pandas\n",
        "# !pip3 install seaborn\n",
        "# !pip3 install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI6cTPdRXYSA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs1_vdyOXYSA",
        "outputId": "6f381cf8-938d-4bf2-dbec-7ea6c8af5a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'layoffs.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9caacd43ac3b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayoff_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'layoffs.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlayoffdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayoff_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'layoffs.csv'"
          ]
        }
      ],
      "source": [
        "layoff_filepath = 'layoffs.csv'\n",
        "layoffdf = pd.read_csv(layoff_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T4vyxwrXYSA"
      },
      "source": [
        "**Since the goal of this project is to predict a new target 'Laid off Quarter' based on feature 'date', we decide to add the new target column here before data processing stage. So we can see the potential relationship between target and other features.**\n",
        "\n",
        "\n",
        "Q1: January, February, March\n",
        "\n",
        "Q2: April, May, June\n",
        "\n",
        "Q3: July, August, September\n",
        "\n",
        "Q4: October, November, December"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5LMi7B3XYSB"
      },
      "outputs": [],
      "source": [
        "date_list = layoffdf['date'].values\n",
        "quarters = []\n",
        "for date in date_list:\n",
        "    y_m_d = date.split(\"-\")\n",
        "    month = int(y_m_d[1])\n",
        "    if (1<= month <= 3):\n",
        "        quarter = 1\n",
        "    elif (4<= month <= 6):\n",
        "        quarter = 2\n",
        "    elif (7<= month <= 9):\n",
        "        quarter = 3\n",
        "    else:\n",
        "        quarter = 4\n",
        "    quarters.append(quarter)\n",
        "layoffdf['quarters'] = quarters\n",
        "layoffdf = layoffdf.drop(columns=['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8TDkGZXYSB"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37C-O5CzXYSC"
      },
      "outputs": [],
      "source": [
        "layoffdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9PKceCDXYSC"
      },
      "outputs": [],
      "source": [
        "layoffdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFf7VoIjXYSC"
      },
      "outputs": [],
      "source": [
        "layoffdf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2eykTygXYSD"
      },
      "outputs": [],
      "source": [
        "columns = layoffdf.columns\n",
        "columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_r9E_OFXYSD"
      },
      "outputs": [],
      "source": [
        "layoffdf.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-dv3nqOXYSD"
      },
      "outputs": [],
      "source": [
        "layoffdf.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1XetHcpXYSD"
      },
      "outputs": [],
      "source": [
        "print(\"Percentage of missing values:\")\n",
        "print(f\"total_laid_off contains {round((1124 / layoffdf.shape[0]) * 100)} % missing values\")\n",
        "print(f\"percentage_laid_off contains {round((1172 / layoffdf.shape[0]) * 100)} % missing values\")\n",
        "print(f\"funds_raised contains {round((351 / layoffdf.shape[0]) * 100)} % missing values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roSJPdYZXYSD"
      },
      "source": [
        "## Data Visualizatoin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHUno1rKXYSD"
      },
      "source": [
        "### Plots for numerical feature: 'total_laid_off'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1VKxoOkXYSD"
      },
      "outputs": [],
      "source": [
        "sns.histplot(layoffdf['total_laid_off'],log_scale=True,kde=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UviAGkaIXYSD"
      },
      "outputs": [],
      "source": [
        "layoffdf['total_laid_off'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pknj-flXYSD"
      },
      "source": [
        "### Plots for numerical feature: 'percentage_laid_off'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh1ygeW5XYSE"
      },
      "outputs": [],
      "source": [
        "sns.histplot(layoffdf['percentage_laid_off'],kde=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6-9XfM6XYSE"
      },
      "outputs": [],
      "source": [
        "layoffdf['percentage_laid_off'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1AwakrBXYSE"
      },
      "source": [
        "### Plots for numerical feature: 'funds_raised'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gULo0yEzXYSE"
      },
      "outputs": [],
      "source": [
        "funds = list(layoffdf['funds_raised'])\n",
        "#get rid of NaN for visualization\n",
        "funds = [x for x in funds if ~np.isnan(x)]\n",
        "#funds contain minimum number 0, which is unable to use log scale\n",
        "min(funds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duXcSTh5XYSE"
      },
      "outputs": [],
      "source": [
        "#log1p adds 1 to all the zero numbers\n",
        "sns.histplot(np.log1p(funds),kde=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE8AJb7kXYSE"
      },
      "outputs": [],
      "source": [
        "layoffdf['funds_raised'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgcNwT3xXYSE"
      },
      "source": [
        "### Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jxcDV-bXYSE"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(layoffdf, hue='quarters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hsOCwm6XYSE"
      },
      "outputs": [],
      "source": [
        "corr = layoffdf.corr()\n",
        "sns.heatmap(corr, vmin=-1, vmax=1, center=0, annot=True, cmap= 'RdBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emUDvR7xXYSE"
      },
      "source": [
        "### Categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzymcNowXYSE"
      },
      "outputs": [],
      "source": [
        "column_names = ['industry', 'stage','location', 'country','company','quarters']\n",
        "for column_name in column_names:\n",
        "    value_counts = layoffdf[column_name].value_counts().head(5)\n",
        "\n",
        "    # Plot a pie chart\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    plt.title(f'Top 5 frequent {column_name}')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    value_counts.plot(kind='bar')\n",
        "    plt.title(f'Frequency in feature {column_name}')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "    print(value_counts.index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMsxpKpGXYSE"
      },
      "outputs": [],
      "source": [
        "column_names = ['industry', 'stage','location', 'country','company']\n",
        "for column_name in column_names:\n",
        "    top_list = layoffdf[column_name].value_counts().head(5).index.tolist()\n",
        "    new_df = layoffdf[layoffdf[column_name].isin(top_list)]\n",
        "\n",
        "    new_df = pd.crosstab(new_df[column_name], new_df['quarters'])\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(new_df, annot=True, fmt='d')\n",
        "    plt.xlabel('Quarter')\n",
        "    plt.ylabel(column_name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ftxpWtOXYSE"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTWqBJ9XXYSE"
      },
      "source": [
        "### Handle missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um06onSVXYSE"
      },
      "source": [
        "We replace the missing numerical values using a descriptive statistic mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT161fZeXYSE"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "columns_to_impute = ['total_laid_off', 'percentage_laid_off', 'funds_raised']\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "layoffdf[columns_to_impute] = imputer.fit_transform(layoffdf[columns_to_impute])\n",
        "layoffdf.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d38byVVXYSE"
      },
      "source": [
        "we drop the rows with missing values for categorical features, since there are only few rows that miss data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvnVesn6XYSF"
      },
      "outputs": [],
      "source": [
        "columns_with_missing = ['location', 'industry', 'stage']\n",
        "layoffdf.dropna(subset=columns_with_missing, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnKzYX9SXYSF"
      },
      "outputs": [],
      "source": [
        "layoffdf.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKhMxUtQXYSF"
      },
      "source": [
        "### Rescale data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiHAJyaMXYSF"
      },
      "source": [
        "plan to use neural network models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5sdNH_bXYSO"
      },
      "outputs": [],
      "source": [
        "layoffdf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saYoDtojXYSO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "columns_to_normalize = ['total_laid_off', 'funds_raised','percentage_laid_off']\n",
        "layoffdf[columns_to_normalize] = min_max_scaler.fit_transform(layoffdf[columns_to_normalize])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BHpQvIiXYSO"
      },
      "outputs": [],
      "source": [
        "layoffdf.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbHjvtijXYSO"
      },
      "outputs": [],
      "source": [
        "layoffdf.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPdcaV4IXYSO"
      },
      "source": [
        "### Transform Categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBZa8NlSXYSO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False, drop='first',handle_unknown='ignore')\n",
        "categorical_cols = ['industry', 'stage','location', 'country','company']\n",
        "encoded_data = encoder.fit_transform(layoffdf[ categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out( categorical_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNcYCq_wXYSO"
      },
      "outputs": [],
      "source": [
        "encoded_df.index = layoffdf.index\n",
        "layoffdf = layoffdf.drop(columns=categorical_cols)\n",
        "layoffdf = pd.concat([layoffdf, encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqzUc6QyXYSO"
      },
      "outputs": [],
      "source": [
        "layoffdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Y1TVkAXYSO"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxa7csbZXYSO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = layoffdf.drop('quarters', axis=1)\n",
        "y = layoffdf['quarters']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frULebQSXYSO"
      },
      "source": [
        "### First Model: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdD-SOUzXYSO"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "model_lg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
        "model_lg.fit(X_train, y_train)\n",
        "y_train_pred = model_lg.predict(X_train)\n",
        "y_test_pred = model_lg.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Plotting\n",
        "plt.bar(['Training error', 'Test error'], [1-train_accuracy, 1-test_accuracy])\n",
        "plt.ylabel('Error')\n",
        "plt.title('Training vs. Test Error')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLFozsVIXYSO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(12, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "model.add(Dense(8, activation='relu'))\n",
        "\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWIRnLefXYSO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}